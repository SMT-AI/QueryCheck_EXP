{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f24d5c-2a90-4fc6-af8e-97408111490f",
   "metadata": {},
   "source": [
    "## Skip Gram Query Check experimental Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276cab7e-7871-4853-910a-cf105a929079",
   "metadata": {},
   "source": [
    "## Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1009b7ba-0e84-4cca-a767-a18ad33eb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1115a68-bc8c-426c-b6cb-3332eb08669a",
   "metadata": {},
   "source": [
    "## TextProcessor -> Count,Filter and get embedding information with word and its id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbb501d3-c939-435f-bb1b-67b0eb011bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self, min_count=5):\n",
    "        self.min_count = min_count\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocabulary_size = 0\n",
    "\n",
    "    def build_vocab(self, texts):\n",
    "        word_counts = Counter()\n",
    "        for text in texts:\n",
    "            words = self._preprocess_text(text)\n",
    "            word_counts.update(words)\n",
    "\n",
    "        filtered_words = [word for word, count in word_counts.items() if count >= self.min_count]\n",
    "\n",
    "        for idx, word in enumerate(filtered_words):\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "\n",
    "        self.vocabulary_size = len(self.word2idx)\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        return text.split()\n",
    "\n",
    "    def text_to_indices(self, text):\n",
    "        words = self._preprocess_text(text)\n",
    "        return [self.word2idx[word] for word in words if word in self.word2idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa1f35-cd0e-466b-9b85-49f7a23bedf7",
   "metadata": {},
   "source": [
    "## Dataset processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff22406-f2fd-4ccd-b35f-4fbc657e1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramDataset(Dataset):\n",
    "    def __init__(self, texts, text_processor, window_size=2):\n",
    "        self.window_size = window_size\n",
    "        self.text_processor = text_processor\n",
    "        self.data = []\n",
    "\n",
    "        for text in texts:\n",
    "            indices = text_processor.text_to_indices(text)\n",
    "\n",
    "        for i in range(len(indices)):\n",
    "            for w in range(-window_size, window_size + 1):\n",
    "                if w == 0:\n",
    "                    continue\n",
    "\n",
    "                context_pos = i + w\n",
    "                if 0 <= context_pos < len(indices):\n",
    "                    self.data.append((indices[i], indices[context_pos]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target, context = self.data[idx]\n",
    "        return torch.tensor(target), torch.tensor(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37abe6-ac7e-4362-903f-e3b209f3cc73",
   "metadata": {},
   "source": [
    "## SkipGram NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d8b9e6c-1197-4257-8fcb-dad7e2ca5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.output = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9983dd00-e6c6-4e26-9ff3-af7812d42c8c",
   "metadata": {},
   "source": [
    "## Training Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "feebeb4f-85c2-4f99-bfcd-168ce5287514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_skipgram(model, train_loader, num_epochs, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch_size, (target, context) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(target)\n",
    "            loss = criterion(output, context)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f31ee-539a-44b8-9ace-7b000dac0920",
   "metadata": {},
   "source": [
    "## Similar words extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c482b8c8-cb23-465d-8e8d-d15dcc4611dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_words(model, word, text_processor, top_k=5):\n",
    "    if word not in text_processor.word2idx:\n",
    "        return []\n",
    "\n",
    "    word_idx = text_processor.word2idx[word]\n",
    "    word_vector = model.embeddings(torch.tensor([word_idx])).detach() #temp detach\n",
    "\n",
    "    similarities = []\n",
    "    for idx in range(text_processor.vocabulary_size):\n",
    "        if idx == word_idx:\n",
    "            continue\n",
    "\n",
    "\n",
    "        other_vector = model.embeddings(torch.tensor([idx])).detach()\n",
    "        similarity = torch.cosine_similarity(word_vector, other_vector)\n",
    "        similarities.append((text_processor.idx2word[idx], similarity.item()))\n",
    "\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa4949-3006-4479-a981-8d1fcd97fa81",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5163d288-5034-48f4-ac79-4cbb03f2b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"wireless bluetooth earbuds with noise isolation\",\n",
    "    \"premium leather bag with hidden compartment\",\n",
    "    \"stainless steel travel mug double walled\",\n",
    "    \"ergonomic office chair with lumbar support\",\n",
    "    \"portable solar charger with dual outputs\",\n",
    "    \"durable hiking boots with waterproof lining\",\n",
    "    \"high-speed USB drive with encryption software\",\n",
    "    \"compact mirrorless camera with zoom lens\",\n",
    "    \"smart fitness tracker with sleep monitor\",\n",
    "    \"noise-cancelling headphones with wireless connectivity\",\n",
    "    \"luxury silk pillowcase with cooling properties\",\n",
    "    \"rechargeable electric toothbrush with timer\",\n",
    "    \"adjustable standing desk with memory settings\",\n",
    "    \"multi-purpose blender with glass pitcher\",\n",
    "    \"heavy-duty toolset with torque wrench\",\n",
    "    \"cordless vacuum cleaner with HEPA filter\",\n",
    "    \"LED desk lamp with wireless charging pad\",\n",
    "    \"waterproof phone case with screen protector\",\n",
    "    \"stainless steel cookware set induction ready\",\n",
    "    \"4K ultra HD smart TV with voice assistant\",\n",
    "    \"wireless mechanical keyboard with tactile feedback\",\n",
    "    \"gaming mouse with customizable RGB lighting\",\n",
    "    \"home security system with motion detection\",\n",
    "    \"electric kettle with temperature presets\",\n",
    "    \"single-serve coffee maker with reusable filter\",\n",
    "    \"digital kitchen scale with tare function\",\n",
    "    \"portable camping stove with piezo ignition\",\n",
    "    \"foldable electric scooter with LED display\",\n",
    "    \"lightweight luggage set with expandable zippers\",\n",
    "    \"baby stroller with adjustable reclining seat\",\n",
    "    \"handheld massage gun with deep tissue capability\",\n",
    "    \"outdoor patio heater with propane tank\",\n",
    "    \"robotic vacuum cleaner with smart mapping\",\n",
    "    \"wireless charging dock with phone stand\",\n",
    "    \"inflatable kayak with reinforced seams\",\n",
    "    \"professional drone with 4K video recording\",\n",
    "    \"noise-isolating headset with detachable microphone\",\n",
    "    \"energy-efficient refrigerator with ice dispenser\",\n",
    "    \"compact air purifier with HEPA filter\",\n",
    "    \"ergonomic gaming chair with footrest extension\",\n",
    "    \"smart thermostat with app integration\",\n",
    "    \"premium yoga mat with alignment lines\",\n",
    "    \"fitness smartwatch with music streaming\",\n",
    "    \"adjustable dumbbells with easy locking mechanism\",\n",
    "    \"electric hair clipper with ceramic blades\",\n",
    "    \"automatic pet feeder with voice recording\",\n",
    "    \"video doorbell with live streaming features\",\n",
    "    \"camping table with aluminum frame\",\n",
    "    \"solar-powered garden lanterns with sensors\",\n",
    "    \"memory foam mattress topper with gel cooling\",\n",
    "    \"outdoor hammock with steel stand\",\n",
    "    \"smart light bulbs with color changing modes\",\n",
    "    \"fire-resistant document bag with lock\",\n",
    "    \"high-performance GPU with ray tracing technology\",\n",
    "    \"waterproof hiking jacket with zip pockets\",\n",
    "    \"stainless steel pressure cooker with timer\",\n",
    "    \"leather laptop sleeve with magnetic closure\",\n",
    "    \"soundproof curtains with thermal insulation\",\n",
    "    \"adjustable baby carrier with padded straps\",\n",
    "    \"mini projector with built-in speaker\",\n",
    "    \"smart water bottle with LED reminders\",\n",
    "    \"LED ring light with adjustable height tripod\",\n",
    "    \"space heater with automatic shutoff feature\",\n",
    "    \"multifunction printer with duplex scanning\",\n",
    "    \"cordless leaf blower with turbo button\",\n",
    "    \"power bank with fast wireless charging\",\n",
    "    \"camping lantern with USB port\",\n",
    "    \"resistance bands with door anchor\",\n",
    "    \"portable air compressor with LED gauge\",\n",
    "    \"touchscreen laptop with 360-degree hinge\",\n",
    "    \"fire pit with mesh safety screen\",\n",
    "    \"kids tablet with educational apps\",\n",
    "    \"dual-band WiFi router with parental controls\",\n",
    "    \"lightweight sleeping bag with waterproof shell\",\n",
    "    \"electric chainsaw with safety brake\",\n",
    "    \"weatherproof tent with double-layer design\",\n",
    "    \"monitor riser with cable management slots\",\n",
    "    \"LED flashlight with zoomable focus\",\n",
    "    \"folding treadmill with heart rate monitor\",\n",
    "    \"smart door lock with fingerprint scanner\",\n",
    "    \"ionic hair dryer with diffuser attachment\",\n",
    "    \"electric pressure washer with adjustable nozzle\",\n",
    "    \"noise-reducing wireless earbuds with bass boost\",\n",
    "    \"gaming monitor with ultra-fast response time\",\n",
    "    \"high-capacity SSD with shock resistance\",\n",
    "    \"ceramic frying pan with nonstick coating\",\n",
    "    \"water-resistant speaker with deep bass\",\n",
    "    \"robot vacuum cleaner with self-emptying bin\",\n",
    "    \"shoe organizer with adjustable tiers\",\n",
    "    \"portable jump starter with safety features\",\n",
    "    \"foldable electric scooter with safety lights\",\n",
    "    \"electric blanket with digital controller\",\n",
    "    \"home gym set with adjustable weights\",\n",
    "    \"programmable coffee maker with milk frother\",\n",
    "    \"smart plug with voice control compatibility\",\n",
    "    \"air mattress with built-in electric pump\",\n",
    "    \"food storage containers with airtight seals\",\n",
    "    \"sewing machine with automatic threader\",\n",
    "    \"cloud-connected digital photo frame\",\n",
    "    \"compact binoculars with waterproof coating\",\n",
    "    \"spacious tent with removable dividers\",\n",
    "    \"solar power bank with multiple ports\",\n",
    "    \"hammock with mosquito net and rain fly\",\n",
    "    \"pressure washer with detergent tank\",\n",
    "    \"ergonomic wireless mouse with silent clicks\",\n",
    "    \"laptop cooling pad with dual fans\",\n",
    "    \"portable fridge with freezer section\",\n",
    "    \"cordless drill with multi-speed settings\",\n",
    "    \"air fryer with touch screen controls\",\n",
    "    \"LED headlamp with adjustable brightness\",\n",
    "    \"car charger with quick charge feature\",\n",
    "    \"hiking poles with foam grips\",\n",
    "    \"standing desk converter with keyboard tray\",\n",
    "    \"solar panel with foldable design\",\n",
    "    \"plush towel set with cotton blend\",\n",
    "    \"smart smoke detector with real-time alerts\",\n",
    "    \"alarm clock with sunrise simulation\",\n",
    "    \"hand vacuum with crevice tool\",\n",
    "    \"fitness watch with calorie counter\",\n",
    "    \"outdoor floodlight with motion detection\",\n",
    "    \"Bluetooth watch with waterproof case\",\n",
    "    \"wireless keyboard with silent keys\",\n",
    "    \"ceramic knife set with block\",\n",
    "    \"inflatable paddleboard with repair kit\",\n",
    "    \"indoor grill with removable plates\",\n",
    "    \"baby gate with safety lock\",\n",
    "    \"tripod stand with phone mount\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b726a3b9-e66a-413c-abc8-cde8664530f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_processor = TextProcessor(min_count=1)\n",
    "text_processor.build_vocab(sample_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0e883c5-5dd1-4aff-9e72-122300e51be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SkipGramDataset(sample_texts, text_processor, window_size=3)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "02483e18-c8b4-400c-aabb-84449d18c94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 6.3083\n",
      "Epoch [2/500], Loss: 5.8922\n",
      "Epoch [3/500], Loss: 5.4841\n",
      "Epoch [4/500], Loss: 5.0837\n",
      "Epoch [5/500], Loss: 4.6912\n",
      "Epoch [6/500], Loss: 4.3078\n",
      "Epoch [7/500], Loss: 3.9356\n",
      "Epoch [8/500], Loss: 3.5779\n",
      "Epoch [9/500], Loss: 3.2387\n",
      "Epoch [10/500], Loss: 2.9231\n",
      "Epoch [11/500], Loss: 2.6360\n",
      "Epoch [12/500], Loss: 2.3818\n",
      "Epoch [13/500], Loss: 2.1633\n",
      "Epoch [14/500], Loss: 1.9811\n",
      "Epoch [15/500], Loss: 1.8338\n",
      "Epoch [16/500], Loss: 1.7176\n",
      "Epoch [17/500], Loss: 1.6272\n",
      "Epoch [18/500], Loss: 1.5570\n",
      "Epoch [19/500], Loss: 1.5020\n",
      "Epoch [20/500], Loss: 1.4582\n",
      "Epoch [21/500], Loss: 1.4231\n",
      "Epoch [22/500], Loss: 1.3949\n",
      "Epoch [23/500], Loss: 1.3727\n",
      "Epoch [24/500], Loss: 1.3557\n",
      "Epoch [25/500], Loss: 1.3433\n",
      "Epoch [26/500], Loss: 1.3348\n",
      "Epoch [27/500], Loss: 1.3293\n",
      "Epoch [28/500], Loss: 1.3258\n",
      "Epoch [29/500], Loss: 1.3235\n",
      "Epoch [30/500], Loss: 1.3216\n",
      "Epoch [31/500], Loss: 1.3197\n",
      "Epoch [32/500], Loss: 1.3176\n",
      "Epoch [33/500], Loss: 1.3154\n",
      "Epoch [34/500], Loss: 1.3130\n",
      "Epoch [35/500], Loss: 1.3105\n",
      "Epoch [36/500], Loss: 1.3081\n",
      "Epoch [37/500], Loss: 1.3059\n",
      "Epoch [38/500], Loss: 1.3040\n",
      "Epoch [39/500], Loss: 1.3025\n",
      "Epoch [40/500], Loss: 1.3016\n",
      "Epoch [41/500], Loss: 1.3010\n",
      "Epoch [42/500], Loss: 1.3008\n",
      "Epoch [43/500], Loss: 1.3007\n",
      "Epoch [44/500], Loss: 1.3006\n",
      "Epoch [45/500], Loss: 1.3004\n",
      "Epoch [46/500], Loss: 1.3000\n",
      "Epoch [47/500], Loss: 1.2996\n",
      "Epoch [48/500], Loss: 1.2991\n",
      "Epoch [49/500], Loss: 1.2985\n",
      "Epoch [50/500], Loss: 1.2981\n",
      "Epoch [51/500], Loss: 1.2977\n",
      "Epoch [52/500], Loss: 1.2974\n",
      "Epoch [53/500], Loss: 1.2972\n",
      "Epoch [54/500], Loss: 1.2970\n",
      "Epoch [55/500], Loss: 1.2969\n",
      "Epoch [56/500], Loss: 1.2968\n",
      "Epoch [57/500], Loss: 1.2967\n",
      "Epoch [58/500], Loss: 1.2966\n",
      "Epoch [59/500], Loss: 1.2965\n",
      "Epoch [60/500], Loss: 1.2963\n",
      "Epoch [61/500], Loss: 1.2962\n",
      "Epoch [62/500], Loss: 1.2961\n",
      "Epoch [63/500], Loss: 1.2960\n",
      "Epoch [64/500], Loss: 1.2959\n",
      "Epoch [65/500], Loss: 1.2958\n",
      "Epoch [66/500], Loss: 1.2957\n",
      "Epoch [67/500], Loss: 1.2956\n",
      "Epoch [68/500], Loss: 1.2956\n",
      "Epoch [69/500], Loss: 1.2955\n",
      "Epoch [70/500], Loss: 1.2954\n",
      "Epoch [71/500], Loss: 1.2954\n",
      "Epoch [72/500], Loss: 1.2953\n",
      "Epoch [73/500], Loss: 1.2953\n",
      "Epoch [74/500], Loss: 1.2952\n",
      "Epoch [75/500], Loss: 1.2952\n",
      "Epoch [76/500], Loss: 1.2952\n",
      "Epoch [77/500], Loss: 1.2951\n",
      "Epoch [78/500], Loss: 1.2951\n",
      "Epoch [79/500], Loss: 1.2950\n",
      "Epoch [80/500], Loss: 1.2950\n",
      "Epoch [81/500], Loss: 1.2949\n",
      "Epoch [82/500], Loss: 1.2949\n",
      "Epoch [83/500], Loss: 1.2949\n",
      "Epoch [84/500], Loss: 1.2948\n",
      "Epoch [85/500], Loss: 1.2948\n",
      "Epoch [86/500], Loss: 1.2948\n",
      "Epoch [87/500], Loss: 1.2948\n",
      "Epoch [88/500], Loss: 1.2947\n",
      "Epoch [89/500], Loss: 1.2947\n",
      "Epoch [90/500], Loss: 1.2946\n",
      "Epoch [91/500], Loss: 1.2946\n",
      "Epoch [92/500], Loss: 1.2946\n",
      "Epoch [93/500], Loss: 1.2946\n",
      "Epoch [94/500], Loss: 1.2945\n",
      "Epoch [95/500], Loss: 1.2945\n",
      "Epoch [96/500], Loss: 1.2945\n",
      "Epoch [97/500], Loss: 1.2945\n",
      "Epoch [98/500], Loss: 1.2944\n",
      "Epoch [99/500], Loss: 1.2944\n",
      "Epoch [100/500], Loss: 1.2944\n",
      "Epoch [101/500], Loss: 1.2944\n",
      "Epoch [102/500], Loss: 1.2943\n",
      "Epoch [103/500], Loss: 1.2943\n",
      "Epoch [104/500], Loss: 1.2943\n",
      "Epoch [105/500], Loss: 1.2943\n",
      "Epoch [106/500], Loss: 1.2942\n",
      "Epoch [107/500], Loss: 1.2942\n",
      "Epoch [108/500], Loss: 1.2942\n",
      "Epoch [109/500], Loss: 1.2942\n",
      "Epoch [110/500], Loss: 1.2941\n",
      "Epoch [111/500], Loss: 1.2941\n",
      "Epoch [112/500], Loss: 1.2941\n",
      "Epoch [113/500], Loss: 1.2941\n",
      "Epoch [114/500], Loss: 1.2941\n",
      "Epoch [115/500], Loss: 1.2940\n",
      "Epoch [116/500], Loss: 1.2940\n",
      "Epoch [117/500], Loss: 1.2940\n",
      "Epoch [118/500], Loss: 1.2940\n",
      "Epoch [119/500], Loss: 1.2940\n",
      "Epoch [120/500], Loss: 1.2939\n",
      "Epoch [121/500], Loss: 1.2939\n",
      "Epoch [122/500], Loss: 1.2939\n",
      "Epoch [123/500], Loss: 1.2939\n",
      "Epoch [124/500], Loss: 1.2939\n",
      "Epoch [125/500], Loss: 1.2938\n",
      "Epoch [126/500], Loss: 1.2938\n",
      "Epoch [127/500], Loss: 1.2938\n",
      "Epoch [128/500], Loss: 1.2938\n",
      "Epoch [129/500], Loss: 1.2938\n",
      "Epoch [130/500], Loss: 1.2937\n",
      "Epoch [131/500], Loss: 1.2937\n",
      "Epoch [132/500], Loss: 1.2937\n",
      "Epoch [133/500], Loss: 1.2937\n",
      "Epoch [134/500], Loss: 1.2937\n",
      "Epoch [135/500], Loss: 1.2936\n",
      "Epoch [136/500], Loss: 1.2936\n",
      "Epoch [137/500], Loss: 1.2936\n",
      "Epoch [138/500], Loss: 1.2936\n",
      "Epoch [139/500], Loss: 1.2936\n",
      "Epoch [140/500], Loss: 1.2936\n",
      "Epoch [141/500], Loss: 1.2935\n",
      "Epoch [142/500], Loss: 1.2935\n",
      "Epoch [143/500], Loss: 1.2935\n",
      "Epoch [144/500], Loss: 1.2935\n",
      "Epoch [145/500], Loss: 1.2935\n",
      "Epoch [146/500], Loss: 1.2935\n",
      "Epoch [147/500], Loss: 1.2934\n",
      "Epoch [148/500], Loss: 1.2934\n",
      "Epoch [149/500], Loss: 1.2934\n",
      "Epoch [150/500], Loss: 1.2934\n",
      "Epoch [151/500], Loss: 1.2934\n",
      "Epoch [152/500], Loss: 1.2934\n",
      "Epoch [153/500], Loss: 1.2933\n",
      "Epoch [154/500], Loss: 1.2933\n",
      "Epoch [155/500], Loss: 1.2933\n",
      "Epoch [156/500], Loss: 1.2933\n",
      "Epoch [157/500], Loss: 1.2933\n",
      "Epoch [158/500], Loss: 1.2933\n",
      "Epoch [159/500], Loss: 1.2932\n",
      "Epoch [160/500], Loss: 1.2932\n",
      "Epoch [161/500], Loss: 1.2932\n",
      "Epoch [162/500], Loss: 1.2932\n",
      "Epoch [163/500], Loss: 1.2932\n",
      "Epoch [164/500], Loss: 1.2932\n",
      "Epoch [165/500], Loss: 1.2932\n",
      "Epoch [166/500], Loss: 1.2931\n",
      "Epoch [167/500], Loss: 1.2931\n",
      "Epoch [168/500], Loss: 1.2931\n",
      "Epoch [169/500], Loss: 1.2931\n",
      "Epoch [170/500], Loss: 1.2931\n",
      "Epoch [171/500], Loss: 1.2931\n",
      "Epoch [172/500], Loss: 1.2931\n",
      "Epoch [173/500], Loss: 1.2930\n",
      "Epoch [174/500], Loss: 1.2930\n",
      "Epoch [175/500], Loss: 1.2930\n",
      "Epoch [176/500], Loss: 1.2930\n",
      "Epoch [177/500], Loss: 1.2930\n",
      "Epoch [178/500], Loss: 1.2930\n",
      "Epoch [179/500], Loss: 1.2930\n",
      "Epoch [180/500], Loss: 1.2929\n",
      "Epoch [181/500], Loss: 1.2929\n",
      "Epoch [182/500], Loss: 1.2929\n",
      "Epoch [183/500], Loss: 1.2929\n",
      "Epoch [184/500], Loss: 1.2929\n",
      "Epoch [185/500], Loss: 1.2929\n",
      "Epoch [186/500], Loss: 1.2929\n",
      "Epoch [187/500], Loss: 1.2929\n",
      "Epoch [188/500], Loss: 1.2928\n",
      "Epoch [189/500], Loss: 1.2928\n",
      "Epoch [190/500], Loss: 1.2928\n",
      "Epoch [191/500], Loss: 1.2928\n",
      "Epoch [192/500], Loss: 1.2928\n",
      "Epoch [193/500], Loss: 1.2928\n",
      "Epoch [194/500], Loss: 1.2928\n",
      "Epoch [195/500], Loss: 1.2928\n",
      "Epoch [196/500], Loss: 1.2928\n",
      "Epoch [197/500], Loss: 1.2927\n",
      "Epoch [198/500], Loss: 1.2927\n",
      "Epoch [199/500], Loss: 1.2927\n",
      "Epoch [200/500], Loss: 1.2927\n",
      "Epoch [201/500], Loss: 1.2927\n",
      "Epoch [202/500], Loss: 1.2927\n",
      "Epoch [203/500], Loss: 1.2927\n",
      "Epoch [204/500], Loss: 1.2927\n",
      "Epoch [205/500], Loss: 1.2926\n",
      "Epoch [206/500], Loss: 1.2926\n",
      "Epoch [207/500], Loss: 1.2926\n",
      "Epoch [208/500], Loss: 1.2926\n",
      "Epoch [209/500], Loss: 1.2926\n",
      "Epoch [210/500], Loss: 1.2926\n",
      "Epoch [211/500], Loss: 1.2926\n",
      "Epoch [212/500], Loss: 1.2926\n",
      "Epoch [213/500], Loss: 1.2926\n",
      "Epoch [214/500], Loss: 1.2926\n",
      "Epoch [215/500], Loss: 1.2925\n",
      "Epoch [216/500], Loss: 1.2925\n",
      "Epoch [217/500], Loss: 1.2925\n",
      "Epoch [218/500], Loss: 1.2925\n",
      "Epoch [219/500], Loss: 1.2925\n",
      "Epoch [220/500], Loss: 1.2925\n",
      "Epoch [221/500], Loss: 1.2925\n",
      "Epoch [222/500], Loss: 1.2925\n",
      "Epoch [223/500], Loss: 1.2925\n",
      "Epoch [224/500], Loss: 1.2925\n",
      "Epoch [225/500], Loss: 1.2924\n",
      "Epoch [226/500], Loss: 1.2924\n",
      "Epoch [227/500], Loss: 1.2924\n",
      "Epoch [228/500], Loss: 1.2924\n",
      "Epoch [229/500], Loss: 1.2924\n",
      "Epoch [230/500], Loss: 1.2924\n",
      "Epoch [231/500], Loss: 1.2924\n",
      "Epoch [232/500], Loss: 1.2924\n",
      "Epoch [233/500], Loss: 1.2924\n",
      "Epoch [234/500], Loss: 1.2924\n",
      "Epoch [235/500], Loss: 1.2924\n",
      "Epoch [236/500], Loss: 1.2923\n",
      "Epoch [237/500], Loss: 1.2923\n",
      "Epoch [238/500], Loss: 1.2923\n",
      "Epoch [239/500], Loss: 1.2923\n",
      "Epoch [240/500], Loss: 1.2923\n",
      "Epoch [241/500], Loss: 1.2923\n",
      "Epoch [242/500], Loss: 1.2923\n",
      "Epoch [243/500], Loss: 1.2923\n",
      "Epoch [244/500], Loss: 1.2923\n",
      "Epoch [245/500], Loss: 1.2923\n",
      "Epoch [246/500], Loss: 1.2923\n",
      "Epoch [247/500], Loss: 1.2923\n",
      "Epoch [248/500], Loss: 1.2922\n",
      "Epoch [249/500], Loss: 1.2922\n",
      "Epoch [250/500], Loss: 1.2922\n",
      "Epoch [251/500], Loss: 1.2922\n",
      "Epoch [252/500], Loss: 1.2922\n",
      "Epoch [253/500], Loss: 1.2922\n",
      "Epoch [254/500], Loss: 1.2922\n",
      "Epoch [255/500], Loss: 1.2922\n",
      "Epoch [256/500], Loss: 1.2922\n",
      "Epoch [257/500], Loss: 1.2922\n",
      "Epoch [258/500], Loss: 1.2922\n",
      "Epoch [259/500], Loss: 1.2922\n",
      "Epoch [260/500], Loss: 1.2921\n",
      "Epoch [261/500], Loss: 1.2921\n",
      "Epoch [262/500], Loss: 1.2921\n",
      "Epoch [263/500], Loss: 1.2921\n",
      "Epoch [264/500], Loss: 1.2921\n",
      "Epoch [265/500], Loss: 1.2921\n",
      "Epoch [266/500], Loss: 1.2921\n",
      "Epoch [267/500], Loss: 1.2921\n",
      "Epoch [268/500], Loss: 1.2921\n",
      "Epoch [269/500], Loss: 1.2921\n",
      "Epoch [270/500], Loss: 1.2921\n",
      "Epoch [271/500], Loss: 1.2921\n",
      "Epoch [272/500], Loss: 1.2921\n",
      "Epoch [273/500], Loss: 1.2921\n",
      "Epoch [274/500], Loss: 1.2920\n",
      "Epoch [275/500], Loss: 1.2920\n",
      "Epoch [276/500], Loss: 1.2920\n",
      "Epoch [277/500], Loss: 1.2920\n",
      "Epoch [278/500], Loss: 1.2920\n",
      "Epoch [279/500], Loss: 1.2920\n",
      "Epoch [280/500], Loss: 1.2920\n",
      "Epoch [281/500], Loss: 1.2920\n",
      "Epoch [282/500], Loss: 1.2920\n",
      "Epoch [283/500], Loss: 1.2920\n",
      "Epoch [284/500], Loss: 1.2920\n",
      "Epoch [285/500], Loss: 1.2920\n",
      "Epoch [286/500], Loss: 1.2920\n",
      "Epoch [287/500], Loss: 1.2920\n",
      "Epoch [288/500], Loss: 1.2920\n",
      "Epoch [289/500], Loss: 1.2920\n",
      "Epoch [290/500], Loss: 1.2919\n",
      "Epoch [291/500], Loss: 1.2919\n",
      "Epoch [292/500], Loss: 1.2919\n",
      "Epoch [293/500], Loss: 1.2919\n",
      "Epoch [294/500], Loss: 1.2919\n",
      "Epoch [295/500], Loss: 1.2919\n",
      "Epoch [296/500], Loss: 1.2919\n",
      "Epoch [297/500], Loss: 1.2919\n",
      "Epoch [298/500], Loss: 1.2919\n",
      "Epoch [299/500], Loss: 1.2919\n",
      "Epoch [300/500], Loss: 1.2919\n",
      "Epoch [301/500], Loss: 1.2919\n",
      "Epoch [302/500], Loss: 1.2919\n",
      "Epoch [303/500], Loss: 1.2919\n",
      "Epoch [304/500], Loss: 1.2919\n",
      "Epoch [305/500], Loss: 1.2919\n",
      "Epoch [306/500], Loss: 1.2918\n",
      "Epoch [307/500], Loss: 1.2918\n",
      "Epoch [308/500], Loss: 1.2918\n",
      "Epoch [309/500], Loss: 1.2918\n",
      "Epoch [310/500], Loss: 1.2918\n",
      "Epoch [311/500], Loss: 1.2918\n",
      "Epoch [312/500], Loss: 1.2918\n",
      "Epoch [313/500], Loss: 1.2918\n",
      "Epoch [314/500], Loss: 1.2918\n",
      "Epoch [315/500], Loss: 1.2918\n",
      "Epoch [316/500], Loss: 1.2918\n",
      "Epoch [317/500], Loss: 1.2918\n",
      "Epoch [318/500], Loss: 1.2918\n",
      "Epoch [319/500], Loss: 1.2918\n",
      "Epoch [320/500], Loss: 1.2918\n",
      "Epoch [321/500], Loss: 1.2918\n",
      "Epoch [322/500], Loss: 1.2918\n",
      "Epoch [323/500], Loss: 1.2918\n",
      "Epoch [324/500], Loss: 1.2918\n",
      "Epoch [325/500], Loss: 1.2917\n",
      "Epoch [326/500], Loss: 1.2917\n",
      "Epoch [327/500], Loss: 1.2917\n",
      "Epoch [328/500], Loss: 1.2917\n",
      "Epoch [329/500], Loss: 1.2917\n",
      "Epoch [330/500], Loss: 1.2917\n",
      "Epoch [331/500], Loss: 1.2917\n",
      "Epoch [332/500], Loss: 1.2917\n",
      "Epoch [333/500], Loss: 1.2917\n",
      "Epoch [334/500], Loss: 1.2917\n",
      "Epoch [335/500], Loss: 1.2917\n",
      "Epoch [336/500], Loss: 1.2917\n",
      "Epoch [337/500], Loss: 1.2917\n",
      "Epoch [338/500], Loss: 1.2917\n",
      "Epoch [339/500], Loss: 1.2917\n",
      "Epoch [340/500], Loss: 1.2917\n",
      "Epoch [341/500], Loss: 1.2917\n",
      "Epoch [342/500], Loss: 1.2917\n",
      "Epoch [343/500], Loss: 1.2917\n",
      "Epoch [344/500], Loss: 1.2917\n",
      "Epoch [345/500], Loss: 1.2917\n",
      "Epoch [346/500], Loss: 1.2916\n",
      "Epoch [347/500], Loss: 1.2916\n",
      "Epoch [348/500], Loss: 1.2916\n",
      "Epoch [349/500], Loss: 1.2916\n",
      "Epoch [350/500], Loss: 1.2916\n",
      "Epoch [351/500], Loss: 1.2916\n",
      "Epoch [352/500], Loss: 1.2916\n",
      "Epoch [353/500], Loss: 1.2916\n",
      "Epoch [354/500], Loss: 1.2916\n",
      "Epoch [355/500], Loss: 1.2916\n",
      "Epoch [356/500], Loss: 1.2916\n",
      "Epoch [357/500], Loss: 1.2916\n",
      "Epoch [358/500], Loss: 1.2916\n",
      "Epoch [359/500], Loss: 1.2916\n",
      "Epoch [360/500], Loss: 1.2916\n",
      "Epoch [361/500], Loss: 1.2916\n",
      "Epoch [362/500], Loss: 1.2916\n",
      "Epoch [363/500], Loss: 1.2916\n",
      "Epoch [364/500], Loss: 1.2916\n",
      "Epoch [365/500], Loss: 1.2916\n",
      "Epoch [366/500], Loss: 1.2916\n",
      "Epoch [367/500], Loss: 1.2916\n",
      "Epoch [368/500], Loss: 1.2916\n",
      "Epoch [369/500], Loss: 1.2915\n",
      "Epoch [370/500], Loss: 1.2915\n",
      "Epoch [371/500], Loss: 1.2915\n",
      "Epoch [372/500], Loss: 1.2915\n",
      "Epoch [373/500], Loss: 1.2915\n",
      "Epoch [374/500], Loss: 1.2915\n",
      "Epoch [375/500], Loss: 1.2915\n",
      "Epoch [376/500], Loss: 1.2915\n",
      "Epoch [377/500], Loss: 1.2915\n",
      "Epoch [378/500], Loss: 1.2915\n",
      "Epoch [379/500], Loss: 1.2915\n",
      "Epoch [380/500], Loss: 1.2915\n",
      "Epoch [381/500], Loss: 1.2915\n",
      "Epoch [382/500], Loss: 1.2915\n",
      "Epoch [383/500], Loss: 1.2915\n",
      "Epoch [384/500], Loss: 1.2915\n",
      "Epoch [385/500], Loss: 1.2915\n",
      "Epoch [386/500], Loss: 1.2915\n",
      "Epoch [387/500], Loss: 1.2915\n",
      "Epoch [388/500], Loss: 1.2915\n",
      "Epoch [389/500], Loss: 1.2915\n",
      "Epoch [390/500], Loss: 1.2915\n",
      "Epoch [391/500], Loss: 1.2915\n",
      "Epoch [392/500], Loss: 1.2915\n",
      "Epoch [393/500], Loss: 1.2915\n",
      "Epoch [394/500], Loss: 1.2915\n",
      "Epoch [395/500], Loss: 1.2915\n",
      "Epoch [396/500], Loss: 1.2914\n",
      "Epoch [397/500], Loss: 1.2914\n",
      "Epoch [398/500], Loss: 1.2914\n",
      "Epoch [399/500], Loss: 1.2914\n",
      "Epoch [400/500], Loss: 1.2914\n",
      "Epoch [401/500], Loss: 1.2914\n",
      "Epoch [402/500], Loss: 1.2914\n",
      "Epoch [403/500], Loss: 1.2914\n",
      "Epoch [404/500], Loss: 1.2914\n",
      "Epoch [405/500], Loss: 1.2914\n",
      "Epoch [406/500], Loss: 1.2914\n",
      "Epoch [407/500], Loss: 1.2914\n",
      "Epoch [408/500], Loss: 1.2914\n",
      "Epoch [409/500], Loss: 1.2914\n",
      "Epoch [410/500], Loss: 1.2914\n",
      "Epoch [411/500], Loss: 1.2914\n",
      "Epoch [412/500], Loss: 1.2914\n",
      "Epoch [413/500], Loss: 1.2914\n",
      "Epoch [414/500], Loss: 1.2914\n",
      "Epoch [415/500], Loss: 1.2914\n",
      "Epoch [416/500], Loss: 1.2914\n",
      "Epoch [417/500], Loss: 1.2914\n",
      "Epoch [418/500], Loss: 1.2914\n",
      "Epoch [419/500], Loss: 1.2914\n",
      "Epoch [420/500], Loss: 1.2914\n",
      "Epoch [421/500], Loss: 1.2914\n",
      "Epoch [422/500], Loss: 1.2914\n",
      "Epoch [423/500], Loss: 1.2914\n",
      "Epoch [424/500], Loss: 1.2914\n",
      "Epoch [425/500], Loss: 1.2914\n",
      "Epoch [426/500], Loss: 1.2914\n",
      "Epoch [427/500], Loss: 1.2913\n",
      "Epoch [428/500], Loss: 1.2913\n",
      "Epoch [429/500], Loss: 1.2913\n",
      "Epoch [430/500], Loss: 1.2913\n",
      "Epoch [431/500], Loss: 1.2913\n",
      "Epoch [432/500], Loss: 1.2913\n",
      "Epoch [433/500], Loss: 1.2913\n",
      "Epoch [434/500], Loss: 1.2913\n",
      "Epoch [435/500], Loss: 1.2913\n",
      "Epoch [436/500], Loss: 1.2913\n",
      "Epoch [437/500], Loss: 1.2913\n",
      "Epoch [438/500], Loss: 1.2913\n",
      "Epoch [439/500], Loss: 1.2913\n",
      "Epoch [440/500], Loss: 1.2913\n",
      "Epoch [441/500], Loss: 1.2913\n",
      "Epoch [442/500], Loss: 1.2913\n",
      "Epoch [443/500], Loss: 1.2913\n",
      "Epoch [444/500], Loss: 1.2913\n",
      "Epoch [445/500], Loss: 1.2913\n",
      "Epoch [446/500], Loss: 1.2913\n",
      "Epoch [447/500], Loss: 1.2913\n",
      "Epoch [448/500], Loss: 1.2913\n",
      "Epoch [449/500], Loss: 1.2913\n",
      "Epoch [450/500], Loss: 1.2913\n",
      "Epoch [451/500], Loss: 1.2913\n",
      "Epoch [452/500], Loss: 1.2913\n",
      "Epoch [453/500], Loss: 1.2913\n",
      "Epoch [454/500], Loss: 1.2913\n",
      "Epoch [455/500], Loss: 1.2913\n",
      "Epoch [456/500], Loss: 1.2913\n",
      "Epoch [457/500], Loss: 1.2913\n",
      "Epoch [458/500], Loss: 1.2913\n",
      "Epoch [459/500], Loss: 1.2913\n",
      "Epoch [460/500], Loss: 1.2913\n",
      "Epoch [461/500], Loss: 1.2913\n",
      "Epoch [462/500], Loss: 1.2913\n",
      "Epoch [463/500], Loss: 1.2912\n",
      "Epoch [464/500], Loss: 1.2912\n",
      "Epoch [465/500], Loss: 1.2912\n",
      "Epoch [466/500], Loss: 1.2912\n",
      "Epoch [467/500], Loss: 1.2912\n",
      "Epoch [468/500], Loss: 1.2912\n",
      "Epoch [469/500], Loss: 1.2912\n",
      "Epoch [470/500], Loss: 1.2912\n",
      "Epoch [471/500], Loss: 1.2912\n",
      "Epoch [472/500], Loss: 1.2912\n",
      "Epoch [473/500], Loss: 1.2912\n",
      "Epoch [474/500], Loss: 1.2912\n",
      "Epoch [475/500], Loss: 1.2912\n",
      "Epoch [476/500], Loss: 1.2912\n",
      "Epoch [477/500], Loss: 1.2912\n",
      "Epoch [478/500], Loss: 1.2912\n",
      "Epoch [479/500], Loss: 1.2912\n",
      "Epoch [480/500], Loss: 1.2912\n",
      "Epoch [481/500], Loss: 1.2912\n",
      "Epoch [482/500], Loss: 1.2912\n",
      "Epoch [483/500], Loss: 1.2912\n",
      "Epoch [484/500], Loss: 1.2912\n",
      "Epoch [485/500], Loss: 1.2912\n",
      "Epoch [486/500], Loss: 1.2912\n",
      "Epoch [487/500], Loss: 1.2912\n",
      "Epoch [488/500], Loss: 1.2912\n",
      "Epoch [489/500], Loss: 1.2912\n",
      "Epoch [490/500], Loss: 1.2912\n",
      "Epoch [491/500], Loss: 1.2912\n",
      "Epoch [492/500], Loss: 1.2912\n",
      "Epoch [493/500], Loss: 1.2912\n",
      "Epoch [494/500], Loss: 1.2912\n",
      "Epoch [495/500], Loss: 1.2912\n",
      "Epoch [496/500], Loss: 1.2912\n",
      "Epoch [497/500], Loss: 1.2912\n",
      "Epoch [498/500], Loss: 1.2912\n",
      "Epoch [499/500], Loss: 1.2912\n",
      "Epoch [500/500], Loss: 1.2912\n"
     ]
    }
   ],
   "source": [
    "model = SkipGramModel(vocab_size=text_processor.vocabulary_size, embedding_dim=500)\n",
    "train_skipgram(model, dataloader, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e98c5a7a-b5b8-49ff-8659-62491e192e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word = \"LED\"\n",
    "similar_words = get_similar_words(model, test_word, text_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "952218cd-bbf0-46b0-bb61-dd1e695d099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Words similar to 'LED':\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nWords similar to '{test_word}':\")\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb2f0ae1-1ecf-414e-a879-8a0e38a30440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compact  bottle\n",
      "stylish  bottle\n",
      "premium  wallet\n",
      "premium  laptop\n",
      "eco-friendly  headphones\n",
      "portable  mouse\n",
      "leather  laptop\n",
      "noise cancelling  headphones\n",
      "noise cancelling stainless steel bottle with\n",
      "compact  keyboard\n",
      "stainless steel  phone\n",
      "premium  tablet\n",
      "eco-friendly  camera\n",
      "vaccum insulated  keyboard\n",
      "wireless  monitor\n",
      "noise cancelling  mouse\n",
      "high quality  laptop\n",
      "noise cancelling portable charger with stainless steel\n",
      "high quality  tablet\n",
      "durable portable camera with\n",
      "stainless steel  camera\n",
      "durable leather charger with\n",
      "stylish  camera\n",
      "vaccum insulated  keyboard\n",
      "high quality  wallet\n",
      "compact  bottle\n",
      "stainless steel  mouse\n",
      "durable portable monitor with stylish\n",
      "durable  watch\n",
      "vaccum insulated premium phone with\n",
      "waterproof stainless steel keyboard with\n",
      "premium  tablet\n",
      "durable  tablet\n",
      "durable leather bottle with lightweight\n",
      "eco-friendly  bottle\n",
      "waterproof  watch\n",
      "wireless  bottle\n",
      "leather lightweight wallet with wireless\n",
      "lightweight compact wallet with\n",
      "eco-friendly eco-friendly watch with stainless steel\n",
      "lightweight  bottle\n",
      "wireless  tablet\n",
      "waterproof  charger\n",
      "eco-friendly  laptop\n",
      "leather lightweight camera with\n",
      "leather  camera\n",
      "lightweight  charger\n",
      "leather  wallet\n",
      "leather  watch\n",
      "stainless steel  mouse\n",
      "stylish stainless steel monitor with compact\n",
      "premium  keyboard\n",
      "stylish  bottle\n",
      "durable  laptop\n",
      "high quality  charger\n",
      "premium high quality phone with premium\n",
      "wireless stylish charger with lightweight\n",
      "premium  watch\n",
      "durable  monitor\n",
      "wireless noise cancelling monitor with high quality\n",
      "leather  camera\n",
      "eco-friendly  keyboard\n",
      "vaccum insulated  charger\n",
      "stylish premium camera with waterproof\n",
      "wireless high quality monitor with\n",
      "stylish durable camera with\n",
      "portable  laptop\n",
      "waterproof  watch\n",
      "wireless  watch\n",
      "vaccum insulated  charger\n",
      "waterproof durable headphones with\n",
      "wireless high quality laptop with\n",
      "high quality  wallet\n",
      "compact  wallet\n",
      "premium  wallet\n",
      "durable durable headphones with stainless steel\n",
      "waterproof  camera\n",
      "noise cancelling  phone\n",
      "wireless  headphones\n",
      "lightweight  laptop\n",
      "vaccum insulated eco-friendly headphones with eco-friendly\n",
      "waterproof  camera\n",
      "compact  headphones\n",
      "premium  wallet\n",
      "eco-friendly  bottle\n",
      "lightweight  tablet\n",
      "portable  headphones\n",
      "noise cancelling  charger\n",
      "wireless  bottle\n",
      "stainless steel  phone\n",
      "eco-friendly  phone\n",
      "noise cancelling  wallet\n",
      "stainless steel  bottle\n",
      "high quality lightweight watch with waterproof\n",
      "vaccum insulated  tablet\n",
      "compact  laptop\n",
      "high quality  laptop\n",
      "premium high quality laptop with compact\n",
      "wireless stylish laptop with vaccum insulated\n",
      "noise cancelling portable bottle with\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Predefined lists of words for generating sample texts\n",
    "nouns = [\n",
    "    \"headphones\", \"wallet\", \"bottle\", \"laptop\", \"phone\", \"watch\",\n",
    "    \"camera\", \"tablet\", \"charger\", \"monitor\", \"keyboard\", \"mouse\"\n",
    "]\n",
    "\n",
    "adjectives = [\n",
    "    \"wireless\", \"premium\", \"stainless steel\", \"leather\", \"waterproof\",\n",
    "    \"noise cancelling\", \"compact\", \"portable\", \"vaccum insulated\",\n",
    "    \"lightweight\", \"durable\", \"high quality\", \"stylish\", \"eco-friendly\"\n",
    "]\n",
    "\n",
    "verbs = [\n",
    "    \"with\", \"and\", \"for\", \"of\", \"from\", \"by\", \"using\", \"to\", \"in\", \"on\"\n",
    "]\n",
    "\n",
    "sample_texts = []\n",
    "\n",
    "# Generate 500 lines of text\n",
    "for _ in range(500):\n",
    "    # Randomly select words from the predefined lists\n",
    "    noun = random.choice(nouns)\n",
    "    adjective1 = random.choice(adjectives)\n",
    "    adjective2 = random.choice(adjectives) if random.random() < 0.3 else \"\"\n",
    "    verb = \"with\" if adjective2 else \"\"  # Use \"with\" only if there's a second adjective\n",
    "    adjective3 = random.choice(adjectives) if adjective2 and random.random() < 0.5 else \"\"\n",
    "    \n",
    "    # Create the sentence with exactly 5 words\n",
    "    text = f\"{adjective1} {adjective2} {noun} {verb} {adjective3}\".strip()\n",
    "    sample_texts.append(text)\n",
    "\n",
    "# Print a few samples to verify the output\n",
    "for i in range(100):\n",
    "    print(sample_texts[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888ac09-e359-4686-91e9-93a531726bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
